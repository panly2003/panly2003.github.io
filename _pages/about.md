---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Hi! My name is **Leyi Pan (潘乐怡)**. I am a second-year PhD student at the [School of Software](https://www.thss.tsinghua.edu.cn/) in [Tsinghua University](https://www.tsinghua.edu.cn/), where I am advised by Prof. [Lijie Wen](https://www.thss.tsinghua.edu.cn/faculty/wenlijie.htm). Before that, I received my B.Eng. degree from the [School of Software](https://www.thss.tsinghua.edu.cn/) in [Tsinghua University](https://www.tsinghua.edu.cn/) in 2024. 

My research areas include:
- Watermark for AIGC, including watermark for large language models and watermark for diffusion models.
- Post-training methods to enhance reasoning capabilities of multimodal large language models.
- Omni-modal large language models (i.e. audio-visual large language models).
- Diffusion large language models (DLLM).

I am currently serving as a Research Intern at [Tongyi Lab of Alibaba](https://careers-tongyi.alibaba.com/), where I am working under the supervision of Dr. [Yunpeng Zhai](https://scholar.google.com/citations?user=YZ88bV8AAAAJ&hl=zh-CN).

Previously, I was working at [Zhipu AI](https://www.zhipuai.cn/) under the supervision of Dr. [Shiyu Huang](http://tartrl.cn/hsy). I also served as a Research Assistant at [CUHK MISC Lab](https://misc-lab.cse.cuhk.edu.hk/), working under the supervision of Prof. [Irwin King](https://www.cse.cuhk.edu.hk/irwin.king/home) (ACM Fellow, IEEE Fellow).

# Education

<div style="display: flex; margin-bottom: 2em; align-items: center;">
    <div style="margin-right: 2em;">
        <img src="images/tsinghua.svg" alt="Tsinghua University Logo" style="width: 80px; height: auto;">
    </div>
    <div>
        <div style="font-weight: bold;">Tsinghua University, China</div>
        <div style="font-style: italic;">PhD Student in Software Engineering</div>
        <div>Sept. 2024 - June 2029 (Expected)</div>
    </div>
</div>

<div style="display: flex; margin-bottom: 2em; align-items: center;">
    <div style="margin-right: 2em;">
        <img src="images/tsinghua.svg" alt="Tsinghua University Logo" style="width: 80px; height: auto;">
    </div>
    <div>
        <div style="font-weight: bold;">Tsinghua University, China</div>
        <div style="font-style: italic;">B.E. in Software Engineering</div>
        <div>Sept. 2020 - June 2024</div>
    </div>
</div>

# Work Experience

<div style="display: flex; margin-bottom: 2em; align-items: center;">
    <div style="margin-right: 2em;">
        <img src="images/qwen-color.svg" alt="Tongyi Logo" style="width: 80px; height: auto;">
    </div>
    <div>
        <div style="font-weight: bold;">Tongyi Lab, Alibaba Group, China</div>
        <div style="font-style: italic;">Research Intern</div>
        <div>Jul. 2025 - Present</div>
    </div>
</div>

<div style="display: flex; margin-bottom: 2em; align-items: center;">
    <div style="margin-right: 2em;">
        <img src="images/zhipu-1.svg" alt="Zhipu Logo" style="width: 80px; height: auto;">
    </div>
    <div>
        <div style="font-weight: bold;">AI Lab, Zhipu AI, China</div>
        <div style="font-style: italic;">Research Intern</div>
        <div>Oct. 2024 - Jun. 2025</div>
    </div>
</div>

<div style="display: flex; margin-bottom: 2em; align-items: center;">
    <div style="margin-right: 2em;">
        <img src="images/cuhk.svg" alt="CUHK Logo" style="width: 80px; height: auto;">
    </div>
    <div>
        <div style="font-weight: bold;">The Chinese University of Hong Kong (CUHK)</div>
        <div style="font-style: italic;">Research Assistant</div>
        <div>Jun. 2024 - Aug. 2024</div>
    </div>
</div>

<div style="display: flex; margin-bottom: 2em; align-items: center;">
    <div style="margin-right: 2em;">
        <img src="images/kuaishou.svg" alt="KuaiShou Logo" style="width: 80px; height: auto;">
    </div>
    <div>
        <div style="font-weight: bold;">KuaiShou Technology, China</div>
        <div style="font-style: italic;">Software Engineer Intern</div>
        <div>Jun. 2023 - Aug. 2023</div>
    </div>
</div>


# Research Paper
### Watermark for AIGC
<div class="paper-container">
<div class="paper-image">
<img src="images/wn.png" alt="paper">
</div>
<div class="paper-text">
<div class="paper-title">Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation?</div>
<p class="paper-authors"><strong style="text-decoration-line: underline;">Leyi Pan</strong>, Aiwei Liu, Shiyu Huang, Yijian Lu, Xuming Hu, Lijie Wen, Irwin King, Philip S. Yu</p>
<p class="paper-venue">Proceedings of ACL 2025</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2502.11598">[Paper]</a> <a href="https://github.com/THU-BPM/Watermark-Radioactivity-Attack">[Code]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/waterseeker.png" alt="paper">
</div>
<div class="paper-text">
<div class="paper-title">WaterSeeker: Pioneering Efficient Detection of Watermarked Segments in Large Documents</div>
<p class="paper-authors"><strong style="text-decoration-line: underline;">Leyi Pan</strong>, Aiwei Liu, Yijian Lu, Zitian Gao, Yichen Di, Shiyu Huang, Lijie Wen, Irwin King, Philip S. Yu</p>
<p class="paper-venue">Findings of NAACL 2025, AAAI 2025 Workshop PDLM (Oral)</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2409.05112">[Paper]</a> <a href="https://github.com/THU-BPM/WaterSeeker">[Code]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/markllm.png" alt="paper">
</div>
<div class="paper-text">
<div class="paper-title">MarkLLM: An Open-Source Toolkit for LLM Watermarking</div>
<p class="paper-authors"><strong style="text-decoration-line: underline;">Leyi Pan</strong>, Aiwei Liu, Zhiwei He, Zitian Gao, Xuandong Zhao, Yijian Lu, Binglin Zhou, Shuliang Liu, Xuming Hu, Lijie Wen, Irwin King, Philip S. Yu</p>
<p class="paper-venue">Proceedings of EMNLP 2024 Demo</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2405.10051">[Paper]</a> <a href="https://github.com/THU-BPM/MarkLLM">[Code]</a> <a href="https://generative-watermark.github.io/">[Homepage]</a> <a href="https://colab.research.google.com/drive/169MS4dY6fKNPZ7-92ETz1bAm_xyNAs0B?usp=sharing">[Google Colab]</a> <a href="https://mp.weixin.qq.com/s/lx9ZNeHae4mo1J6_sFubfg">[机器之心]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/markdiffusion.png" alt="paper">
</div>
<div class="paper-text">
<div class="paper-title">MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models</div>
<p class="paper-authors"><strong style="text-decoration-line: underline;">Leyi Pan</strong>, Sheng Guan, Zheyu Fu, Luyang Si, Zian Wang, Xuming Hu, Irwin King, Philip S. Yu, Aiwei Liu, Lijie Wen</p>
<p class="paper-venue">arXiv preprint. arXiv:2509.10569</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2509.10569">[Paper]</a> <a href="https://github.com/THU-BPM/MarkDiffusion">[Code]</a> <a href="https://generative-watermark.github.io/">[Homepage]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/survey.png" alt="paper">
</div>
<div class="paper-text">
<div class="paper-title">A Survey of Text Watermarking in the Era of Large Language Models</div>
<p class="paper-authors">Aiwei Liu*, <strong style="text-decoration-line: underline;">Leyi Pan*</strong>, Yijian Lu, Jingjing Li, Xuming Hu, Xi Zhang, Lijie Wen, Irwin King, Hui Xiong, Philip S. Yu</p>
<p class="paper-venue">ACM Computing Surveys</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2312.07913.pdf">[Paper]</a> <a href="https://survey-text-watermark.github.io/">[Home]</a> <a href="https://mp.weixin.qq.com/s/U3ZzGsi3Yihueqr6MGRHfg">[机器之心]</a> <a href="https://x.com/Aiwei_Liu_99/status/1821673541026099519">[Twitter]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/probe.png" alt="paper">
</div>
<div class="paper-text">
<div class="paper-title">Can Watermarked LLMs be Identified by Users via Crafted Prompts?</div>
<p class="paper-authors">Aiwei Liu, Sheng Guan, Yiming Liu, <strong style="text-decoration-line: underline;">Leyi Pan</strong>, Yifei Zhang, Liancheng Fang, Lijie Wen, Philip S. Yu, Xuming Hu</p>
<p class="paper-venue">Proceedings of ICLR 2025</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2410.03168">[Paper]</a> <a href="https://github.com/THU-BPM/Watermarked_LLM_Identification">[Code]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/SIR.png" alt="paper">
</div>
<div class="paper-text">
<div class="paper-title">A Semantic Invariant Robust Watermark for Large Language Models</div>
<p class="paper-authors">Aiwei Liu, <strong style="text-decoration-line: underline;">Leyi Pan</strong>, Xuming Hu, Shiao Meng, Lijie Wen</p>
<p class="paper-venue">Proceedings of ICLR 2024</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2310.06356.pdf">[Paper]</a> <a href="https://github.com/THU-BPM/Robust_Watermark">[Code]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/UPV.png" alt="paper">
</div>
<div class="paper-text">
<div class="paper-title">An Unforgeable Publicly Verifiable Watermark for Large Language Models</div>
<p class="paper-authors">Aiwei Liu, <strong style="text-decoration-line: underline;">Leyi Pan</strong>, Xuming Hu, Shuang Li, Lijie Wen, Irwin King, Philip S. Yu</p>
<p class="paper-venue">Proceedings of ICLR 2024</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2307.16230.pdf">[Paper]</a> <a href="https://github.com/THU-BPM/unforgeable_watermark">[Code]</a></p>
</div>
</div>

### MLLM Reasoning
<div class="paper-container">
<div class="paper-image">
<img src="images/GLM-4.1V-Thinking.png" alt="paper">
</div>
<div class="paper-text">
<div class="paper-title">GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning</div>
<p class="paper-authors">Wenyi Hong, Wenmeng Yu, Xiaotao Gu, Guo Wang, Guobing Gan, Haomiao Tang, Jiale Cheng, Ji Qi, Junhui Ji, Lihang Pan, Shuaiqi Duan, Weihan Wang, Yan Wang, Yean Cheng, Zehai He, Zhe Su, Zhen Yang, Ziyang Pan, Aohan Zeng, Baoxu Wang, Boyan Shi, Changyu Pang, Chenhui Zhang, Da Yin, Fan Yang, Guoqing Chen, Jiazheng Xu, Jiali Chen, Jing Chen, Jinhao Chen, Jinghao Lin, Jinjiang Wang, Junjie Chen, Leqi Lei, <strong style="text-decoration-line: underline;">Leyi Pan</strong>, Mingzhi Zhang, Qinkai Zheng, Sheng Yang, Shi Zhong, Shiyu Huang, Shuyuan Zhao, Siyan Xue, Shangqin Tu, Shengbiao Meng, Tianshu Zhang, Tianwei Luo, Tianxiang Hao, Tianle Gong, Wenkai Li, Wei Jia, Xin Lyu, Xuancheng Huang, Yanling Wang, Yadong Xue, Yanfeng Wang, Yifan An, Yifan Du, Yiming Shi, Yiheng Huang, Yilin Niu, Yuan Wang, Yuanchang Yue, Yuchen Li, Yutao Zhang, Yuxuan Zhang, Zhanxiao Du, Zhenyu Hou, Zhao Xue, Zhengxiao Du, Zihan Wang, Peng Zhang, Debing Liu, Bin Xu, Juanzi Li, Minlie Huang, Yuxiao Dong, Jie Tang</p>
<p class="paper-venue">Technical Report of GLM-4.1V-Thinking</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2507.01006">[Technical Report]</a> <a href="https://github.com/THUDM/GLM-4.1V-Thinking">[Code]</a></p>
</div>
</div>

### Omni-modal Large Language Models
<div class="paper-container">
<div class="paper-image">
<img src="images/Omni-SafetyBench.png" alt="paper">
</div>
<div class="paper-text">
<div class="paper-title">Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models</div>
<p class="paper-authors"><strong style="text-decoration-line: underline;">Leyi Pan</strong>, Zheyu Fu, Yunpeng Zhai, Shuchang Tao, Sheng Guan, Shiyu Huang, Lingzhe Zhang, Zhaoyang Liu, Bolin Ding, Felix Henry, Lijie Wen, Aiwei Liu</p>
<p class="paper-venue">arXiv preprint. arXiv:2508.07173</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2508.07173.pdf">[Paper]</a> <a href="https://github.com/THU-BPM/Omni-SafetyBench">[Code]</a> <a href="https://huggingface.co/datasets/Leyiii/Omni-SafetyBench">[Data]</a></p>
</div>
</div>

<div class="paper-container">
<div class="paper-image">
<img src="images/OmniPlay.png" alt="paper">
</div>
<div class="paper-text">
<div class="paper-title">OmniPlay: Benchmarking Omni-Modal Models on Omni-Modal Game Playing</div>
<p class="paper-authors">Fuqing Bie, Shiyu Huang, Xijia Tao, Zhiqin Fang, <strong style="text-decoration-line: underline;">Leyi Pan</strong>, Junzhe Chen, Min Ren, Liuyu Xiang, Zhaofeng He</p>
<p class="paper-venue">arXiv preprint. arXiv:2508.04361</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2508.04361.pdf">[Paper]</a> <a href="https://github.com/fuqingbie/omni-game-benchmark">[Code]</a></p>
</div>
</div>

### Diffusion Large Language Models
<div class="paper-container">
<div class="paper-image">
<img src="images/dllm-survey.png" alt="paper">
</div>
<div class="paper-text">
<div class="paper-title">A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models</div>
<p class="paper-authors">Lingzhe Zhang*, Liancheng Fang*, Chiming Duan*, Minghua He*, <strong style="text-decoration-line: underline;">Leyi Pan*</strong>, Pei Xiao, Shiyu Huang, Yunpeng Zhai, Xuming Hu, Philip S. Yu, Aiwei Liu*</p>
<p class="paper-venue">arXiv preprint. arXiv:2508.08712</p>
<p class="paper-links"><a href="https://arxiv.org/pdf/2508.08712.pdf">[Paper]</a></p>
</div>
</div>

# Project
<div style="display: flex; flex-direction: column; gap: 20px;">
    <!-- MarkLLM Card -->
    <div style="
        border: 1px solid #e1e4e8;
        border-radius: 6px;
        padding: 16px;
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif;
        background-color: #fff;
    ">
        <div style="display: flex; justify-content: space-between; align-items: center;">
            <div>
                <svg height="16" viewBox="0 0 16 16" version="1.1" width="16">
                    <path fill-rule="evenodd" d="M2 2.5A2.5 2.5 0 014.5 0h8.75a.75.75 0 01.75.75v12.5a.75.75 0 01-.75.75h-2.5a.75.75 0 110-1.5h1.75v-2h-8a1 1 0 00-.714 1.7.75.75 0 01-1.072 1.05A2.495 2.495 0 012 11.5v-9zm10.5-1V9h-8c-.356 0-.694.074-1 .208V2.5a1 1 0 011-1h8zM5 12.25v3.25a.25.25 0 00.4.2l1.45-1.087a.25.25 0 01.3 0L8.6 15.7a.25.25 0 00.4-.2v-3.25a.25.25 0 00-.25-.25h-3.5a.25.25 0 00-.25.25z" fill="#586069"></path>
                </svg>
                <a href="https://github.com/THU-BPM/MarkLLM" style="
                    color: #0366d6;
                    text-decoration: none;
                    font-weight: 600;
                    font-size: 14px;
                    margin-left: 8px;
                ">THU-BPM/MarkLLM</a>
            </div>
            <div style="
                border: 1px solid #e1e4e8;
                border-radius: 20px;
                padding: 0 7px;
                font-size: 12px;
                color: #586069;
            ">Public</div>
        </div>
        <p style="
            font-size: 14px;
            color: #586069;
            margin: 8px 0;
        "><span style="color: #238636; font-weight: 500;">🏆 First Author & First Contributor</span><br> An Open-Source Toolkit for LLM Watermarking (EMNLP 2024 Demo)
        </p>
        <div style="display: flex; align-items: center; margin-top: 8px; gap: 8px;">
            <!-- Language -->
            <img src="https://img.shields.io/github/languages/top/THU-BPM/MarkLLM?style=flat-square" alt="Language">
            <!-- Stars -->
            <img src="https://img.shields.io/github/stars/THU-BPM/MarkLLM?style=flat-square" alt="Stars">
            <!-- Forks -->
            <img src="https://img.shields.io/github/forks/THU-BPM/MarkLLM?style=flat-square" alt="Forks">
            <!-- Last Commit -->
            <img src="https://img.shields.io/github/last-commit/THU-BPM/MarkLLM?style=flat-square" alt="Last Commit">
        </div>
    </div>
</div>

<br>

<div style="display: flex; flex-direction: column; gap: 20px;">
    <!-- MarkDiffusion Card -->
    <div style="
        border: 1px solid #e1e4e8;
        border-radius: 6px;
        padding: 16px;
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif;
        background-color: #fff;
    ">
        <div style="display: flex; justify-content: space-between; align-items: center;">
            <div>
                <svg height="16" viewBox="0 0 16 16" version="1.1" width="16">
                    <path fill-rule="evenodd" d="M2 2.5A2.5 2.5 0 014.5 0h8.75a.75.75 0 01.75.75v12.5a.75.75 0 01-.75.75h-2.5a.75.75 0 110-1.5h1.75v-2h-8a1 1 0 00-.714 1.7.75.75 0 01-1.072 1.05A2.495 2.495 0 012 11.5v-9zm10.5-1V9h-8c-.356 0-.694.074-1 .208V2.5a1 1 0 011-1h8zM5 12.25v3.25a.25.25 0 00.4.2l1.45-1.087a.25.25 0 01.3 0L8.6 15.7a.25.25 0 00.4-.2v-3.25a.25.25 0 00-.25-.25h-3.5a.25.25 0 00-.25.25z" fill="#586069"></path>
                </svg>
                <a href="https://github.com/THU-BPM/MarkDiffusion" style="
                    color: #0366d6;
                    text-decoration: none;
                    font-weight: 600;
                    font-size: 14px;
                    margin-left: 8px;
                ">THU-BPM/MarkDiffusion</a>
            </div>
            <div style="
                border: 1px solid #e1e4e8;
                border-radius: 20px;
                padding: 0 7px;
                font-size: 12px;
                color: #586069;
            ">Public</div>
        </div>
        <p style="
            font-size: 14px;
            color: #586069;
            margin: 8px 0;
        "><span style="color: #238636; font-weight: 500;">🏆 First Author </span><br> An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models
        </p>
        <div style="display: flex; align-items: center; margin-top: 8px; gap: 8px;">
            <!-- Language -->
            <img src="https://img.shields.io/github/languages/top/THU-BPM/MarkDiffusion?style=flat-square" alt="Language">
            <!-- Stars -->
            <img src="https://img.shields.io/github/stars/THU-BPM/MarkDiffusion?style=flat-square" alt="Stars">
            <!-- Forks -->
            <img src="https://img.shields.io/github/forks/THU-BPM/MarkDiffusion?style=flat-square" alt="Forks">
            <!-- Last Commit -->
            <img src="https://img.shields.io/github/last-commit/THU-BPM/MarkDiffusion?style=flat-square" alt="Last Commit">
        </div>
    </div>
</div>

<br>

<!-- GLM-4.1V-Thinking Card -->
<div style="display: flex; flex-direction: column; gap: 20px;">
    <div style="
        border: 1px solid #e1e4e8;
        border-radius: 6px;
        padding: 16px;
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif;
        background-color: #fff;
    ">
        <div style="display: flex; justify-content: space-between; align-items: center;">
            <div>
                <svg height="16" viewBox="0 0 16 16" version="1.1" width="16">
                    <path fill-rule="evenodd" d="M2 2.5A2.5 2.5 0 014.5 0h8.75a.75.75 0 01.75.75v12.5a.75.75 0 01-.75.75h-2.5a.75.75 0 110-1.5h1.75v-2h-8a1 1 0 00-.714 1.7.75.75 0 01-1.072 1.05A2.495 2.495 0 012 11.5v-9zm10.5-1V9h-8c-.356 0-.694.074-1 .208V2.5a1 1 0 011-1h8zM5 12.25v3.25a.25.25 0 00.4.2l1.45-1.087a.25.25 0 01.3 0L8.6 15.7a.25.25 0 00.4-.2v-3.25a.25.25 0 00-.25-.25h-3.5a.25.25 0 00-.25.25z" fill="#586069"></path>
                </svg>
                <a href="https://github.com/THUDM/GLM-4.1V-Thinking" style="
                    color: #0366d6;
                    text-decoration: none;
                    font-weight: 600;
                    font-size: 14px;
                    margin-left: 8px;
                ">THUDM/GLM-4.1V-Thinking</a>
            </div>
            <div style="
                border: 1px solid #e1e4e8;
                border-radius: 20px;
                padding: 0 7px;
                font-size: 12px;
                color: #586069;
            ">Public</div>
        </div>
        <p style="
            font-size: 14px;
            color: #586069;
            margin: 8px 0;
        ">GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning
        </p>
        <div style="display: flex; align-items: center; margin-top: 8px; gap: 8px;">
            <!-- Language -->
            <img src="https://img.shields.io/github/languages/top/THUDM/GLM-4.1V-Thinking?style=flat-square" alt="Language">
            <!-- Stars -->
            <img src="https://img.shields.io/github/stars/THUDM/GLM-4.1V-Thinking?style=flat-square" alt="Stars">
            <!-- Forks -->
            <img src="https://img.shields.io/github/forks/THUDM/GLM-4.1V-Thinking?style=flat-square" alt="Forks">
            <!-- Last Commit -->
            <img src="https://img.shields.io/github/last-commit/THUDM/GLM-4.1V-Thinking?style=flat-square" alt="Last Commit">
        </div>
    </div>
</div>

<br>

<div style="display: flex; flex-direction: column; gap: 20px;">
    <!-- Omni-SafetyBench Card -->
    <div style="
        border: 1px solid #e1e4e8;
        border-radius: 6px;
        padding: 16px;
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif;
        background-color: #fff;
    ">
        <div style="display: flex; justify-content: space-between; align-items: center;">
            <div>
                <svg height="16" viewBox="0 0 16 16" version="1.1" width="16">
                    <path fill-rule="evenodd" d="M2 2.5A2.5 2.5 0 014.5 0h8.75a.75.75 0 01.75.75v12.5a.75.75 0 01-.75.75h-2.5a.75.75 0 110-1.5h1.75v-2h-8a1 1 0 00-.714 1.7.75.75 0 01-1.072 1.05A2.495 2.495 0 012 11.5v-9zm10.5-1V9h-8c-.356 0-.694.074-1 .208V2.5a1 1 0 011-1h8zM5 12.25v3.25a.25.25 0 00.4.2l1.45-1.087a.25.25 0 01.3 0L8.6 15.7a.25.25 0 00.4-.2v-3.25a.25.25 0 00-.25-.25h-3.5a.25.25 0 00-.25.25z" fill="#586069"></path>
                </svg>
                <a href="https://github.com/THU-BPM/Omni-SafetyBench" style="
                    color: #0366d6;
                    text-decoration: none;
                    font-weight: 600;
                    font-size: 14px;
                    margin-left: 8px;
                ">THU-BPM/Omni-SafetyBench</a>
            </div>
            <div style="
                border: 1px solid #e1e4e8;
                border-radius: 20px;
                padding: 0 7px;
                font-size: 12px;
                color: #586069;
            ">Public</div>
        </div>
        <p style="
            font-size: 14px;
            color: #586069;
            margin: 8px 0;
        "><span style="color: #238636; font-weight: 500;">🏆 First Author & First Contributor</span><br> Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models
        </p>
        <div style="display: flex; align-items: center; margin-top: 8px; gap: 8px;">
            <!-- Language -->
            <img src="https://img.shields.io/github/languages/top/THU-BPM/Omni-SafetyBench?style=flat-square" alt="Language">
            <!-- Stars -->
            <img src="https://img.shields.io/github/stars/THU-BPM/Omni-SafetyBench?style=flat-square" alt="Stars">
            <!-- Forks -->
            <img src="https://img.shields.io/github/forks/THU-BPM/Omni-SafetyBench?style=flat-square" alt="Forks">
            <!-- Last Commit -->
            <img src="https://img.shields.io/github/last-commit/THU-BPM/Omni-SafetyBench?style=flat-square" alt="Last Commit">
        </div>
    </div>
</div>

<br>

# Awards
- **Outstanding Graduate of Beijing** (北京市优秀毕业生)
- **Outstanding Graduate of Tsinghua** (清华大学优良毕业生)
- **Tsinghua Outstanding Graduation Project** (清华大学优秀毕业设计)
- **Tsinghua Excellent Student Award** (清华大学综合优秀奖学金)
- **Outstanding Student Cadre of Tsinghua University** (清华大学优秀学生干部)

# Contact

- **Email**:
  -  panly24@mails.tsinghua.edu.cn
  -  panleyi2003@gmail.com


# Services
- **Reviewer**:
  - ACL ARR 2025 May Reviewer
  - The 2025 Conference on Empirical Methods in Natural Language Processing, System Demonstration Track (EMNLP 2025 Demo)
  - The Thirty-Ninth Annual Conference on Neural Information Processing Systems (NIPS 2025)
  - The Thirteenth International Conference on Learning Representations (ICLR 2025)

<p align="center" style="padding-top: 100px;"> 
</p>

<style>
.paper-container {
    display: flex;
    gap: 20px;
    margin: 30px 0;
    padding: 15px;
    border-radius: 8px;
    background: #fff;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

hr {
    margin: 10px 0;
    height: 1px;
    background-color: #ddd;
    border: none;
}

.paper-image {
    flex: 0 0 300px;
    min-width: 0;
}

.paper-image img {
    width: 100%;
    height: auto;
    border-radius: 4px;
    border: 1px solid #eee;
}

.paper-text {
    flex: 1;
    min-width: 0;
}


.paper-title {
  font-family: "Microsoft YaHei",
  font-weight: 2000;
  -webkit-text-stroke: 0.9px black;  /* 添加描边效果使文字看起来更粗 */
  font-size: 18px;
  margin: 0 0 8px 0;
  color: #000;
}

.paper-authors {
  font-family: "Microsoft YaHei",
   margin: 2px 0;
    font-size: 14.5px;         /* 调小作者字体 */
    color: rgba(0,0,0,0.9);    /* 更自然的灰色 */
    font-weight: 400;          /* 更细的字重 */
}

.paper-venue {
   font-family: "Microsoft YaHei",
    color: #d83931;
    font-style: italic;
    font-size: 0.95em;
    margin: 3px 0;
}

.paper-links {
  font-family: "Microsoft YaHei",
    font-size: 0.9em;
    margin: 3px 0;
}

.paper-links a {
    margin-right: 10px;
    color: #4A90E2;
    text-decoration: none;
    transition: color 0.2s ease;
}

.paper-links a:hover {
    color: #357ABD;
}

@media (max-width: 768px) {
    .paper-container {
        flex-direction: column;
    }
    
    .paper-image {
        flex: 0 0 auto;
        width: 100%;
    }
}
</style>